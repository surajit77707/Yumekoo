import asyncio
from openai import OpenAI
from pyrogram import Client, filters
from pyrogram.types import Message
from Yumeko import app
from config import config
from Yumeko.decorator.save import save 
from Yumeko.decorator.errors import error
from lexica import Client as LexicaClient, languageModels

# Initialize OpenAI client
openai_client = OpenAI(api_key=config.OPENAI_KEY)
MODEL = "gpt-3.5-turbo"


def askgemini(prompt: str) -> dict:
    client = LexicaClient()
    response = client.ChatCompletion(prompt, languageModels.gemini)
    return response

@app.on_message(filters.command("askgpt" , config.COMMAND_PREFIXES))
@error
@save
async def ask_openai(client: Client, message: Message):
    if len(message.command) < 2:
        await message.reply("ğ–´ğ—Œğ–ºğ—€ğ–¾: /ğ–ºğ—Œğ—„ğ—€ğ—‰ğ— <ğ—‰ğ—‹ğ—ˆğ—†ğ—‰ğ—>")
        return

    prompt = message.text.split(maxsplit=1)[1]
    processing_message = await message.reply("ğŸ’­ ğ–³ğ—ğ—‚ğ—‡ğ—„ğ—‚ğ—‡ğ—€... ğ–¯ğ—…ğ–¾ğ–ºğ—Œğ–¾ ğ—ğ–ºğ—‚ğ—")

    try:
        # Call OpenAI API for a streaming response
        stream = openai_client.chat.completions.create(
            model=MODEL,
            messages=[{"role": "system", "content": "You are a helpful assistant."},
                      {"role": "user", "content": prompt}],
            stream=True,
        )

        response_text = ""
        last_edit_time = 0  # Track the time of the last message edit
        for chunk in stream:
            content = chunk.choices[0].delta.content
            if content:
                response_text += content

                # Only edit the message if enough time has passed
                current_time = asyncio.get_event_loop().time()
                if current_time - last_edit_time > 2:  # Edit every 1.5 seconds
                    await processing_message.edit(response_text)
                    last_edit_time = current_time

        # Ensure final response is updated
        if response_text.strip():
            await processing_message.edit(response_text.strip())
        else:
            await processing_message.edit("ğ–¨ ğ–¼ğ—ˆğ—ğ—…ğ–½ğ—‡'ğ— ğ—€ğ–¾ğ—‡ğ–¾ğ—‹ğ–ºğ—ğ–¾ ğ–º ğ—‹ğ–¾ğ—Œğ—‰ğ—ˆğ—‡ğ—Œğ–¾. ğ–¯ğ—…ğ–¾ğ–ºğ—Œğ–¾ ğ—ğ—‹ğ—’ ğ–ºğ—€ğ–ºğ—‚ğ—‡.")

    except Exception as e:
        print(e)
        await processing_message.edit(f"ğ– ğ—‡ ğ–¾ğ—‹ğ—‹ğ—ˆğ—‹ ğ—ˆğ–¼ğ–¼ğ—ğ—‹ğ—‹ğ–¾ğ–½ : {e}")
 

# /ask command handler
@app.on_message(filters.command("askgemini", config.COMMAND_PREFIXES))
async def ask_handler(client, message):
    try:
        # Get the query after the command
        query = " ".join(message.command[1:])
        if not query:
            await message.reply_text("Please provide a prompt after the /askgemini command.")
            return

        # Call the Lexica API
        a = await message.reply_text("ğŸ’­")
        response = askgemini(query)
        content = response["content"][0]["text"] 
        
        # Format and send the response
        if response:
            await a.edit_text(f"**Response:**\n{content}")
        else:
            await a.edit_text("No response from the Gemini.")
    except Exception as e:
        await a.edit_text(f"An error occurred")
        

__module__ = "ğ– ğ—Œğ—„"
__help__ = """âœ§ /askgpt <prompt> : ğ–´ğ—Œğ–¾ ğ–¦ğ–¯ğ–³-3.5-ğ—ğ—ğ—‹ğ–»ğ—ˆ ğ—ğ—ˆ ğ—€ğ–¾ğ—‡ğ–¾ğ—‹ğ–ºğ—ğ–¾ ğ—‹ğ–¾ğ—Œğ—‰ğ—ˆğ—‡ğ—Œğ–¾ğ—Œ.
âœ§ /askgemini <prompt> : ğ–´ğ—Œğ–¾ ğ–«ğ–¾ğ—‘ğ—‚ğ–¼ğ–º'ğ—Œ ğ–¦ğ–¾ğ—†ğ—‚ğ—‡ğ—‚ ğ—…ğ–ºğ—‡ğ—€ğ—ğ–ºğ—€ğ–¾ ğ—†ğ—ˆğ–½ğ–¾ğ—… ğ—ğ—ˆ ğ—€ğ–¾ğ—‡ğ–¾ğ—‹ğ–ºğ—ğ–¾ ğ—‹ğ–¾ğ—Œğ—‰ğ—ˆğ—‡ğ—Œğ–¾ğ—Œ."""
